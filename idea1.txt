Build a Python-based automated reel generator with the following strict
specifications.

This is a deterministic media pipeline. Do not simplify logic.

ğŸ¯ OBJECTIVE

Given:

A user-provided script (~30 seconds)

A fixed intro image (3 seconds)

A fixed outro image (3 seconds)

A list of middle images

The system must:

Generate voiceover from the script using a TTS API.

Measure exact audio duration.

Distribute timing equally across middle images.

Generate a video using FFmpeg.

Add synced captions.

Ensure precise synchronization between:

Intro

Voiceover

Image durations

Captions

Outro

Final video duration must be:

3 (intro) + voice_duration + 3 (outro)

ğŸ“¥ INPUT FORMAT

The system should accept:

{ â€œscriptâ€: str, â€œintro_imageâ€: str, â€œoutro_imageâ€: str,
â€œmiddle_imagesâ€: List[str], â€œvoice_settingsâ€: { â€œvoice_idâ€: str,
â€œspeedâ€: float } }

âš™ï¸ STEP 1 â€” VOICEOVER

Use a TTS API (design as pluggable).

Save as voiceover.mp3.

Measure exact duration using ffprobe or librosa.

Store duration as float (no rounding).

âš™ï¸ STEP 2 â€” TIMING LOGIC

Let:

intro_duration = 3 outro_duration = 3 middle_duration = voice_duration
image_count = len(middle_images) per_image_duration = middle_duration /
image_count

Do NOT round values.

âš™ï¸ STEP 3 â€” CAPTION GENERATION

Generate captions from script.

Requirements:

Split script into logical sentence chunks.

Distribute captions evenly across voice_duration.

Caption timing must:

Start at 3 seconds

End at 3 + voice_duration

Each caption must have:

start_time

end_time

text

Output captions in .srt format.

Example:

1 00:00:03,000 â€“> 00:00:07,000 Breaking news todayâ€¦

2 00:00:07,000 â€“> 00:00:11,000 Markets show strong growthâ€¦

Caption timing must align proportionally across the voice duration.

Do NOT estimate speech timing per word. Just distribute evenly across
chunks.

âš™ï¸ STEP 4 â€” VIDEO GENERATION

Use FFmpeg to:

Create intro clip (3s from intro image)

Create middle clips:

Each image duration = per_image_duration

Apply subtle zoom/pan effect

Create outro clip (3s)

Concatenate all clips

Add voiceover with 3 second delay

Burn captions into video

Audio must start at 3 seconds using adelay=3000|3000.

âš™ï¸ STEP 5 â€” CAPTION BURN-IN

Use FFmpeg subtitles filter:

-vf subtitles=captions.srt

Caption styling:

Font size: medium-large

White text

Black shadow

Bottom center alignment

ğŸ§  EDGE CASES TO HANDLE

No middle images â†’ raise error

Voice duration < 3 seconds â†’ reject

Image count too large â†’ ensure per_image_duration > 0.5s minimum

TTS failure â†’ retry once

FFmpeg failure â†’ raise structured error

ğŸ“‚ PROJECT STRUCTURE /reel_generator main.py tts.py video_builder.py
caption_generator.py utils.py /temp /output

ğŸ“¤ FINAL OUTPUT

The system should output:

{ â€œvoice_durationâ€: float, â€œper_image_durationâ€: float,
â€œfinal_video_durationâ€: float, â€œoutput_fileâ€: â€œfinal_reel.mp4â€ }

No console prints except structured logging.

ğŸš« DO NOT

Do not estimate duration from text length.

Do not modify the script.

Do not hardcode durations except intro/outro.

Do not use magic numbers.

Do not assume FPS â€” explicitly define it.

Do not use external video editing libraries (only FFmpeg via
subprocess).

ğŸ¥ OPTIONAL IMPROVEMENT (IF IMPLEMENTING CLEANLY)

Make zoom direction alternate per image for dynamic feel.

END OF SPECIFICATION

Generate full Python implementation with:

Clean modular code

Clear function boundaries

Error handling

Logging

FFmpeg command construction

Comments explaining synchronization logic

Do not simplify architecture.
